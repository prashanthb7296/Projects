{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NLP Basics**"
      ],
      "metadata": {
        "id": "t9LQUg_QrwqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Prashanth B"
      ],
      "metadata": {
        "id": "qJ96_CYUrzw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy Installation"
      ],
      "metadata": {
        "id": "SeD3gjr1zHuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AoodtzJ1uhis",
        "outputId": "f5f717ba-2b2a-44e6-f639-b6ba48ad04ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FTZ3otaVuvpV",
        "outputId": "1be98f5b-714e-4bfe-dfb9-58fe5692e4fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-09 18:22:02.414035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create blank language object and tokenize words in a sentence"
      ],
      "metadata": {
        "id": "TXZbwgAURT8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7SoBpvA8RLhP",
        "outputId": "8c09a8ba-91ae-41dc-9312-ee99d11c53a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f264440c820>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w7-hv5gKRLkC",
        "outputId": "b1aaac17-c170-49c5-f3d9-88e27052af16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GFO5dMEwRLm5",
        "outputId": "ebd49ef2-f413-472f-aea8-16cc931379ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            "as\n",
            "it\n",
            "costs\n",
            "only\n",
            "2\n",
            "$\n",
            "per\n",
            "plate\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JEmZjcS8RLp2",
        "outputId": "dec266a2-280c-47a2-ac78-c01c20e67eef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YIq0PkfzR2N7",
        "outputId": "583555e5-cd1b-4fd9-b8fd-ad3bc2f0ed3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nl9P9aNvRLtI",
        "outputId": "52768079-a1ef-4bff-b774-5616add2c18f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "url5aXxQR5Ks",
        "outputId": "00babe4e-2d0f-4b17-fb53-7f8e79d04211"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KzonRd21RLv1",
        "outputId": "750fd791-cae3-445b-a9cb-75b246c94f87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_dep',\n",
              " 'has_extension',\n",
              " 'has_head',\n",
              " 'has_morph',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'iob_strings',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_end',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'set_morph',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dir(token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jbECvchYRLyi",
        "outputId": "9fbc6326-2874-4a2a-d820-397167f897b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T946IQy9RL1h",
        "outputId": "8d8e7c96-25ec-489b-bc53-5ffad38a54f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rsnWsqh5RL4f",
        "outputId": "2c80d8e6-9607-457e-ead2-1cecf7686483"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PUwi0g60SWac",
        "outputId": "2d5bfd77-68f4-46cf-ca08-b38b0e2be55b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i5X5NIiSSWdC",
        "outputId": "ae66e556-31ee-4d62-ad0c-de0773a756ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wcTebCosSWfk",
        "outputId": "0dad7c30-1dad-48bd-e239-4ef864920278"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr. Strange loves pav bhaji"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4w0H3ldlSWiW",
        "outputId": "e0fcc4e8-fb66-48a5-c437-1bb0d49ec4ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Token attributes\n",
        "doc = nlp(\"Tony gave two $ to Peter.\")"
      ],
      "metadata": {
        "id": "TuP4McT6SWk7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token0 = doc[0]\n",
        "token0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KSSvlf7ASWn4",
        "outputId": "119b350b-cbef-4e01-be25-e4e3d93a8f3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tony"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token0.is_alpha, token0.like_num, token0.is_currency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EAz6VKomSWql",
        "outputId": "5cee4921-2ec4-49fc-fa67-863fad70fb98"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token1 = doc[1]\n",
        "token1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x49Q1sewRL8B",
        "outputId": "d9abdfdb-c476-4005-d936-79ca8b1ac122"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gave"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token1.is_alpha, token1.like_num, token1.is_currency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1LjmYiePRL-l",
        "outputId": "6e83ad49-77a3-4486-d021-b1750bf60e87"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2 = doc[2]\n",
        "token2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3GYAWa4nRMBS",
        "outputId": "ac697a74-7610-451f-bfdd-7f68eee4dd8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "two"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2.is_alpha, token2.like_num, token2.is_currency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YtUHe-znRMER",
        "outputId": "52e5bf42-c7aa-4448-a54b-fbd7dbd23b44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, False)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token3 = doc[3]\n",
        "token3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sXY4Sfu_TsRq",
        "outputId": "30b5e205-3b03-49da-c884-02d759d1cd81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token3.is_alpha, token3.like_num, token3.is_currency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JnPfXhP8TsUq",
        "outputId": "09d9e639-9694-42df-9b4c-c834bf47866f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token, \"  |  \", \"index:\", token.i, \"  |  \",\n",
        "          \"is_alpha:\", token.is_alpha, \"  |  \",\n",
        "          \"is_punct:\", token.is_punct, \"  |  \",\n",
        "          \"like_num:\", token.like_num, \"  |  \",\n",
        "          \"is_currency:\", token.is_currency,\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2XNFhOubTsXE",
        "outputId": "5f97f93f-d5aa-421e-b976-951d29107592"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tony   |   index: 0   |   is_alpha: True   |   is_punct: False   |   like_num: False   |   is_currency: False\n",
            "gave   |   index: 1   |   is_alpha: True   |   is_punct: False   |   like_num: False   |   is_currency: False\n",
            "two   |   index: 2   |   is_alpha: True   |   is_punct: False   |   like_num: True   |   is_currency: False\n",
            "$   |   index: 3   |   is_alpha: False   |   is_punct: False   |   like_num: False   |   is_currency: True\n",
            "to   |   index: 4   |   is_alpha: True   |   is_punct: False   |   like_num: False   |   is_currency: False\n",
            "Peter   |   index: 5   |   is_alpha: True   |   is_punct: False   |   like_num: False   |   is_currency: False\n",
            ".   |   index: 6   |   is_alpha: False   |   is_punct: True   |   like_num: False   |   is_currency: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting Email IDs of students from students information sheet"
      ],
      "metadata": {
        "id": "2HR7csS0UbSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = ['Virat   5 June, 1882    virat@kohli.com',\n",
        " 'Maria   12 April, 2001  maria@sharapova.com',\n",
        " 'Serena  24 June, 1998   serena@williams.com',\n",
        " 'Joe      1 May, 1997    joe@root.com']"
      ],
      "metadata": {
        "id": "0-AGIrOqT3im"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(l)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JafIvDBsT3nK",
        "outputId": "fd58912c-d433-486d-dfbe-2c02247d156f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Virat   5 June, 1882    virat@kohli.com Maria   12 April, 2001  maria@sharapova.com Serena  24 June, 1998   serena@williams.com Joe      1 May, 1997    joe@root.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-58lqWwrTsZh",
        "outputId": "57233114-360d-4adf-e251-4dd1b7590076"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Virat   5 June, 1882    virat@kohli.com Maria   12 April, 2001  maria@sharapova.com Serena  24 June, 1998   serena@williams.com Joe      1 May, 1997    joe@root.com"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emails = []\n",
        "for token in doc:\n",
        "  if token.like_email:\n",
        "    emails.append(token.text)\n",
        "emails"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2pACJETiTscH",
        "outputId": "ffdfa08a-2294-46f5-a707-0569138a996d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['virat@kohli.com',\n",
              " 'maria@sharapova.com',\n",
              " 'serena@williams.com',\n",
              " 'joe@root.com']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support in other languages"
      ],
      "metadata": {
        "id": "niLu94YAVMq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"hi\")\n",
        "nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4-j1EUA9Tsez",
        "outputId": "02832a17-2bad-41e0-830e-6164a94b4a07"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.hi.Hindi at 0x7f2643fd1a50>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WH5vg1ZzTsh2",
        "outputId": "a716d093-37a1-41d5-a0b8-aabcabc8878b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "भैया जी! 5000 ₹ उधार थे वो वापस देदो"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token, \"---\", token.is_currency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GOHZYprQTsjv",
        "outputId": "b674e6cd-4ec4-4ff3-dc4c-2b8f032ebb28"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "भैया --- False\n",
            "जी --- False\n",
            "! --- False\n",
            "5000 --- False\n",
            "₹ --- True\n",
            "उधार --- False\n",
            "थे --- False\n",
            "वो --- False\n",
            "वापस --- False\n",
            "देदो --- False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing tokenizer"
      ],
      "metadata": {
        "id": "DB_qF6E2Vw5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH"
      ],
      "metadata": {
        "id": "eJcvzVdqVni3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wfLKWoAnVqfU",
        "outputId": "185b654b-ac0b-4835-bd55-9df27c98e944"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gimme double cheese extra large healthy pizza"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q8ncimlUVqiA",
        "outputId": "2a757722-d0cf-4e9e-c21c-d47417034bf7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer.add_special_case(\"gimme\", [{ORTH: \"gim\"}, {ORTH: \"me\"}])"
      ],
      "metadata": {
        "id": "g6fNlvGpVqkt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O1KyIAF4Vnld",
        "outputId": "0377f889-6953-4931-fe60-50ded17ca3ac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Tokenization or Segmentation"
      ],
      "metadata": {
        "id": "cZlXwXEkWa7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DUPZzNVSVnn7",
        "outputId": "0037f1b1-2fae-4e9b-9cd8-d74ab795a547"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "DkUP-l-QVnrW",
        "outputId": "17de3801-e8eb-45ec-98d2-24ba79c85409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-5e8ad1b67b91>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5ZA9hCBTVnuA",
        "outputId": "ea0e6c1d-eb6e-498d-f83d-ab2d90c0ba5e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uGC-0lqLVnwO",
        "outputId": "0cc875ee-e3e9-4b59-9812-cc30c08d1ddd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7f2643ffbbc0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "16ClP98oWxis",
        "outputId": "b20d7647-5d55-4b95-a31e-c73f9ede185d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x7f2643ffbbc0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F8wGRGmzWxfR",
        "outputId": "c833b4fa-dd2d-4f72-ebe7-31c1697c09d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mumbai.\n",
            "Hulk loves chat of delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipelines Tutorial"
      ],
      "metadata": {
        "id": "TT3l0AKMXBlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UijfSz6JWxly",
        "outputId": "59e719a4-2129-40ea-8523-08cb393e2e80"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Captain america ate 100$ of samosa. Then he said I can do this all day."
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cLEaGotGXKLr",
        "outputId": "9843676b-4b61-4196-d29a-5824522d9f95"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "I\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "day\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sP5uUTW9XKOW",
        "outputId": "067bcdbb-0eb8-48ec-873d-8ebd7500455c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(name = 'en_core_web_md')\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5-aIkqu6XKRP",
        "outputId": "949f2e54-0e46-4bce-b3d9-8e7c33170b2f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "98ANZn0aXKT2",
        "outputId": "b5e26dce-cc8c-483c-950f-75f72e263124"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f2643cf0b80>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f2643cf0ac0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f2643ce44a0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f2643c21900>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f2643a8b2c0>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f2643ce46d0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "for token in doc:\n",
        "  print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RfVvPF6YXKWN",
        "outputId": "994ea443-499c-41c4-f64e-07524d5dae37"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |  proper noun  |  Captain\n",
            "america  |  proper noun  |  america\n",
            "ate  |  verb  |  eat\n",
            "100  |  numeral  |  100\n",
            "$  |  noun  |  $\n",
            "of  |  adposition  |  of\n",
            "samosa  |  proper noun  |  samosa\n",
            ".  |  punctuation  |  .\n",
            "Then  |  adverb  |  then\n",
            "he  |  pronoun  |  he\n",
            "said  |  verb  |  say\n",
            "I  |  pronoun  |  I\n",
            "can  |  auxiliary  |  can\n",
            "do  |  verb  |  do\n",
            "this  |  pronoun  |  this\n",
            "all  |  determiner  |  all\n",
            "day  |  noun  |  day\n",
            ".  |  punctuation  |  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "CnqYcqxKaXzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sq_M1L2pXKZH",
        "outputId": "b8446aa5-9815-4be7-df99-82ce5a2c9d2f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tesla Inc is going to acquire twitter for $45 billion"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc.ents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Pnhb53-malK3",
        "outputId": "05154e47-70b6-4a0b-d6cd-e8252297266f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Tesla Inc, $45 billion)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, \"---\", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OebfAch4XKc-",
        "outputId": "459c44d9-525c-42fd-a367-ab348046c45e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc --- ORG\n",
            "$45 billion --- MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_labels['ner']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k006W6H3XNM-",
        "outputId": "98a4d3f1-3455-4c52-f1e4-67359e555286"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CARDINAL',\n",
              " 'DATE',\n",
              " 'EVENT',\n",
              " 'FAC',\n",
              " 'GPE',\n",
              " 'LANGUAGE',\n",
              " 'LAW',\n",
              " 'LOC',\n",
              " 'MONEY',\n",
              " 'NORP',\n",
              " 'ORDINAL',\n",
              " 'ORG',\n",
              " 'PERCENT',\n",
              " 'PERSON',\n",
              " 'PRODUCT',\n",
              " 'QUANTITY',\n",
              " 'TIME',\n",
              " 'WORK_OF_ART']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Michael Bloomberg founded Bloomberg in 1982\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GUQWYICAXbRS",
        "outputId": "0585112b-e0ea-45b0-ae6a-71df9a0ec434"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Michael Bloomberg founded Bloomberg in 1982"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R15k-IDFXeSh",
        "outputId": "19ed00c0-d485-4347-b165-ead9a09937bf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Bloomberg  |  PERSON  |  People, including fictional\n",
            "Bloomberg  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "1982  |  DATE  |  Absolute or relative dates or periods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla is going to acquire Twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UUAI_JKrXo7v",
        "outputId": "44ae6318-a44d-431e-f44a-6ad50562e59e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla  |  ORG\n",
            "Twitter  |  ORG\n",
            "$45 billion  |  MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting custom entities"
      ],
      "metadata": {
        "id": "2I08n_ZbZiGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Threads is going to acquire Twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OQ3iOoB8ZkwU",
        "outputId": "664c73a5-49ea-4cb4-d00e-d3599a207452"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Twitter  |  ORG\n",
            "$45 billion  |  MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = doc[0:1]\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9rEQDbLbZ7HI",
        "outputId": "b7519a15-2b54-464d-99ea-596a846dfe43"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Threads"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "STAyOm2baAgb",
        "outputId": "3ce41453-51f9-4af3-8f8f-3a04b548c7c5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span\n",
        "s1 = Span(doc, 0, 1, label=\"ORG\")\n",
        "doc.set_ents([s1], default=\"unmodified\")"
      ],
      "metadata": {
        "id": "ytMnAmlfaCN6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yTVxvP_5aK0B",
        "outputId": "1c9d3110-a0c2-4a5d-eae0-c586c4893890"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads  |  ORG\n",
            "Twitter  |  ORG\n",
            "$45 billion  |  MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming in NLTK"
      ],
      "metadata": {
        "id": "JJeVWGRlzu9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "FVZLE9V2Wxnl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]"
      ],
      "metadata": {
        "id": "qk02V5KkbAhp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word, \"  |  \", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "59xKq0LSbAkd",
        "outputId": "6394ee34-b8e6-4fa2-a569-19af1caf9740"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating   |   eat\n",
            "eats   |   eat\n",
            "eat   |   eat\n",
            "ate   |   ate\n",
            "adjustable   |   adjust\n",
            "rafting   |   raft\n",
            "ability   |   abil\n",
            "meeting   |   meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization in Spacy"
      ],
      "metadata": {
        "id": "GWSzKQZiz95V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
        "doc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xPvLp9aAbApQ",
        "outputId": "a0214253-f224-46d4-8056-e32be010df52"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mando talked for 3 hours although talking isn't his thing"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc1:\n",
        "  print(token, \" --- \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cM1AXuZBWxpq",
        "outputId": "b5c53f79-e45d-4bb9-95b4-ca6593e3f786"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mando  ---  Mando\n",
            "talked  ---  talk\n",
            "for  ---  for\n",
            "3  ---  3\n",
            "hours  ---  hour\n",
            "although  ---  although\n",
            "talking  ---  talk\n",
            "is  ---  be\n",
            "n't  ---  not\n",
            "his  ---  his\n",
            "thing  ---  thing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "for token in doc2:\n",
        "    print(token, \" --- \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kO6fB6sAWxse",
        "outputId": "570f9b4a-e5af-41b2-b62f-12bce6e81271"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  ---  eating\n",
            "eats  ---  eat\n",
            "eat  ---  eat\n",
            "ate  ---  eat\n",
            "adjustable  ---  adjustable\n",
            "rafting  ---  rafting\n",
            "ability  ---  ability\n",
            "meeting  ---  meet\n",
            "better  ---  well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing lemmatizer"
      ],
      "metadata": {
        "id": "KMeRr-7Y0a-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tG1coBvvWxvC",
        "outputId": "ba1f6b56-9b1e-4f25-c6a0-6f5ad68a78c7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')"
      ],
      "metadata": {
        "id": "aSxlsKpzWxxj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "  print(token.text, \"  ---  \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4dKfyP6k0jK0",
        "outputId": "cadcdf63-9395-4811-d992-73b04a034c2e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro   ---   Brother\n",
            ",   ---   ,\n",
            "you   ---   you\n",
            "wanna   ---   wanna\n",
            "go   ---   go\n",
            "?   ---   ?\n",
            "Brah   ---   Brother\n",
            ",   ---   ,\n",
            "do   ---   do\n",
            "n't   ---   not\n",
            "say   ---   say\n",
            "no   ---   no\n",
            "!   ---   !\n",
            "I   ---   I\n",
            "am   ---   be\n",
            "exhausted   ---   exhausted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[6], doc[6].lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0y2zI3mF0jNw",
        "outputId": "46694b90-6f64-4e17-8b58-371367aff496"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Brah, 'Brother')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts of Speech (POS) Tags"
      ],
      "metadata": {
        "id": "V_rRbl1M07E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Elon flew to mars yesterday. He carried tesla with him\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r7Fg4pyq0jQb",
        "outputId": "7ab29882-7aa6-4cc1-fe68-7fb0fae2dd81"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Elon flew to mars yesterday. He carried tesla with him"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ezJmEmgc0jTK",
        "outputId": "24524df5-3e98-4689-8ad6-48f9c64818b0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon  |  PROPN  |  proper noun\n",
            "flew  |  VERB  |  verb\n",
            "to  |  ADP  |  adposition\n",
            "mars  |  PROPN  |  proper noun\n",
            "yesterday  |  NOUN  |  noun\n",
            ".  |  PUNCT  |  punctuation\n",
            "He  |  PRON  |  pronoun\n",
            "carried  |  VERB  |  verb\n",
            "tesla  |  NOUN  |  noun\n",
            "with  |  ADP  |  adposition\n",
            "him  |  PRON  |  pronoun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n",
        "\n",
        "for token in doc2:\n",
        "    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YJ0A-FRX0jV0",
        "outputId": "0d71285e-1bcb-44c5-83d9-7f2278fdfe65"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow  |  INTJ  |  interjection\n",
            "!  |  PUNCT  |  punctuation\n",
            "Dr.  |  PROPN  |  proper noun\n",
            "Strange  |  PROPN  |  proper noun\n",
            "made  |  VERB  |  verb\n",
            "265  |  NUM  |  numeral\n",
            "million  |  NUM  |  numeral\n",
            "$  |  SYM  |  symbol\n",
            "on  |  ADP  |  adposition\n",
            "the  |  DET  |  determiner\n",
            "very  |  ADV  |  adverb\n",
            "first  |  ADJ  |  adjective\n",
            "day  |  NOUN  |  noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tags"
      ],
      "metadata": {
        "id": "8s6cW7fz2eYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc2:\n",
        "    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_), \" | \",\n",
        "          token.tag_, \" | \", spacy.explain(token.tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2k8CqTbm0jar",
        "outputId": "1a895c94-f124-47d4-fd25-0b6e28df7f36"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow  |  INTJ  |  interjection  |  UH  |  interjection\n",
            "!  |  PUNCT  |  punctuation  |  .  |  punctuation mark, sentence closer\n",
            "Dr.  |  PROPN  |  proper noun  |  NNP  |  noun, proper singular\n",
            "Strange  |  PROPN  |  proper noun  |  NNP  |  noun, proper singular\n",
            "made  |  VERB  |  verb  |  VBD  |  verb, past tense\n",
            "265  |  NUM  |  numeral  |  CD  |  cardinal number\n",
            "million  |  NUM  |  numeral  |  CD  |  cardinal number\n",
            "$  |  SYM  |  symbol  |  $  |  symbol, currency\n",
            "on  |  ADP  |  adposition  |  IN  |  conjunction, subordinating or preposition\n",
            "the  |  DET  |  determiner  |  DT  |  determiner\n",
            "very  |  ADV  |  adverb  |  RB  |  adverb\n",
            "first  |  ADJ  |  adjective  |  JJ  |  adjective (English), other noun-modifier (Chinese)\n",
            "day  |  NOUN  |  noun  |  NN  |  noun, singular or mass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"He quits the job\")\n",
        "doc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DJWOvEJp0jcq",
        "outputId": "41fc0e35-bf0e-4165-aa29-4b72dbaac2cf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quits"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[1].text, \"  |  \", doc[1].tag_, \"  |  \", spacy.explain(doc[1].tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J0T-rSX52x-M",
        "outputId": "e9837bd7-9e87-4b26-f1f7-2c333da0d907"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quits   |   VBZ   |   verb, 3rd person singular present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"he quit the job\")\n",
        "print(doc[1].text, \"  |  \", doc[1].tag_, \"  |  \", spacy.explain(doc[1].tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pfgxWsre21V9",
        "outputId": "4ba177f6-ea34-4f27-d781-1333ff786475"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quit   |   VBD   |   verb, past tense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing all SPACE, PUNCT and X token from text"
      ],
      "metadata": {
        "id": "DyPsbl853SgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "earnings_text=\"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31,\n",
        "                  2021, as compared to the corresponding period of last fiscal year:\n",
        "\n",
        "·         Revenue was $51.7 billion and increased 20%\n",
        "·         Operating income was $22.2 billion and increased 24%\n",
        "·         Net income was $18.8 billion and increased 21%\n",
        "·         Diluted earnings per share was $2.48 and increased 22%\n",
        "“Digital technology is the most malleable resource at the world’s disposal to overcome constraints\n",
        "and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft.\n",
        "“As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse\n",
        "and growing markets, with a common underlying technology stack and an operating model that reinforces a\n",
        "common strategy, culture, and sense of purpose.”\n",
        "“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments,\n",
        "increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive\n",
        "vice president and chief financial officer of Microsoft.\"\"\""
      ],
      "metadata": {
        "id": "aMlWYahi3Ds5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(earnings_text)\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MPvX6ruz3wu-",
        "outputId": "aa2a8c02-c0e7-4e7d-a1d2-50fc276e4772"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Microsoft Corp. today announced the following results for the quarter ended December 31,\n",
              "                  2021, as compared to the corresponding period of last fiscal year:\n",
              "\n",
              "·         Revenue was $51.7 billion and increased 20%\n",
              "·         Operating income was $22.2 billion and increased 24%\n",
              "·         Net income was $18.8 billion and increased 21%\n",
              "·         Diluted earnings per share was $2.48 and increased 22%\n",
              "“Digital technology is the most malleable resource at the world’s disposal to overcome constraints\n",
              "and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft.\n",
              "“As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse\n",
              "and growing markets, with a common underlying technology stack and an operating model that reinforces a\n",
              "common strategy, culture, and sense of purpose.”\n",
              "“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments,\n",
              "increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive\n",
              "vice president and chief financial officer of Microsoft."
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, \"  |  \", token.pos_, \"  |  \", spacy.explain(token.pos_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y3TBpgy630HU",
        "outputId": "38ac710f-a9a9-498c-b35b-f60b5036bc13"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft   |   PROPN   |   proper noun\n",
            "Corp.   |   PROPN   |   proper noun\n",
            "today   |   NOUN   |   noun\n",
            "announced   |   VERB   |   verb\n",
            "the   |   DET   |   determiner\n",
            "following   |   VERB   |   verb\n",
            "results   |   NOUN   |   noun\n",
            "for   |   ADP   |   adposition\n",
            "the   |   DET   |   determiner\n",
            "quarter   |   NOUN   |   noun\n",
            "ended   |   VERB   |   verb\n",
            "December   |   PROPN   |   proper noun\n",
            "31   |   NUM   |   numeral\n",
            ",   |   PUNCT   |   punctuation\n",
            "\n",
            "                     |   SPACE   |   space\n",
            "2021   |   NUM   |   numeral\n",
            ",   |   PUNCT   |   punctuation\n",
            "as   |   ADP   |   adposition\n",
            "compared   |   VERB   |   verb\n",
            "to   |   ADP   |   adposition\n",
            "the   |   DET   |   determiner\n",
            "corresponding   |   ADJ   |   adjective\n",
            "period   |   NOUN   |   noun\n",
            "of   |   ADP   |   adposition\n",
            "last   |   ADJ   |   adjective\n",
            "fiscal   |   ADJ   |   adjective\n",
            "year   |   NOUN   |   noun\n",
            ":   |   PUNCT   |   punctuation\n",
            "\n",
            "\n",
            "   |   SPACE   |   space\n",
            "·   |   PUNCT   |   punctuation\n",
            "           |   SPACE   |   space\n",
            "Revenue   |   NOUN   |   noun\n",
            "was   |   AUX   |   auxiliary\n",
            "$   |   SYM   |   symbol\n",
            "51.7   |   NUM   |   numeral\n",
            "billion   |   NUM   |   numeral\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "increased   |   VERB   |   verb\n",
            "20   |   NUM   |   numeral\n",
            "%   |   NOUN   |   noun\n",
            "\n",
            "   |   SPACE   |   space\n",
            "·   |   PUNCT   |   punctuation\n",
            "           |   SPACE   |   space\n",
            "Operating   |   VERB   |   verb\n",
            "income   |   NOUN   |   noun\n",
            "was   |   AUX   |   auxiliary\n",
            "$   |   SYM   |   symbol\n",
            "22.2   |   NUM   |   numeral\n",
            "billion   |   NUM   |   numeral\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "increased   |   VERB   |   verb\n",
            "24   |   NUM   |   numeral\n",
            "%   |   NOUN   |   noun\n",
            "\n",
            "   |   SPACE   |   space\n",
            "·   |   PUNCT   |   punctuation\n",
            "           |   SPACE   |   space\n",
            "Net   |   ADJ   |   adjective\n",
            "income   |   NOUN   |   noun\n",
            "was   |   AUX   |   auxiliary\n",
            "$   |   SYM   |   symbol\n",
            "18.8   |   NUM   |   numeral\n",
            "billion   |   NUM   |   numeral\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "increased   |   VERB   |   verb\n",
            "21   |   NUM   |   numeral\n",
            "%   |   NOUN   |   noun\n",
            "\n",
            "   |   SPACE   |   space\n",
            "·   |   PUNCT   |   punctuation\n",
            "           |   SPACE   |   space\n",
            "Diluted   |   ADJ   |   adjective\n",
            "earnings   |   NOUN   |   noun\n",
            "per   |   ADP   |   adposition\n",
            "share   |   NOUN   |   noun\n",
            "was   |   AUX   |   auxiliary\n",
            "$   |   SYM   |   symbol\n",
            "2.48   |   NUM   |   numeral\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "increased   |   VERB   |   verb\n",
            "22   |   NUM   |   numeral\n",
            "%   |   NOUN   |   noun\n",
            "\n",
            "   |   SPACE   |   space\n",
            "“   |   PUNCT   |   punctuation\n",
            "Digital   |   ADJ   |   adjective\n",
            "technology   |   NOUN   |   noun\n",
            "is   |   AUX   |   auxiliary\n",
            "the   |   DET   |   determiner\n",
            "most   |   ADV   |   adverb\n",
            "malleable   |   ADJ   |   adjective\n",
            "resource   |   NOUN   |   noun\n",
            "at   |   ADP   |   adposition\n",
            "the   |   DET   |   determiner\n",
            "world   |   NOUN   |   noun\n",
            "’s   |   PART   |   particle\n",
            "disposal   |   NOUN   |   noun\n",
            "to   |   PART   |   particle\n",
            "overcome   |   VERB   |   verb\n",
            "constraints   |   NOUN   |   noun\n",
            "\n",
            "   |   SPACE   |   space\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "reimagine   |   VERB   |   verb\n",
            "everyday   |   ADJ   |   adjective\n",
            "work   |   NOUN   |   noun\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "life   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "”   |   PUNCT   |   punctuation\n",
            "said   |   VERB   |   verb\n",
            "Satya   |   PROPN   |   proper noun\n",
            "Nadella   |   PROPN   |   proper noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "chairman   |   NOUN   |   noun\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "chief   |   ADJ   |   adjective\n",
            "executive   |   ADJ   |   adjective\n",
            "officer   |   NOUN   |   noun\n",
            "of   |   ADP   |   adposition\n",
            "Microsoft   |   PROPN   |   proper noun\n",
            ".   |   PUNCT   |   punctuation\n",
            "\n",
            "   |   SPACE   |   space\n",
            "“   |   PUNCT   |   punctuation\n",
            "As   |   ADV   |   adverb\n",
            "tech   |   NOUN   |   noun\n",
            "as   |   ADP   |   adposition\n",
            "a   |   DET   |   determiner\n",
            "percentage   |   NOUN   |   noun\n",
            "of   |   ADP   |   adposition\n",
            "global   |   ADJ   |   adjective\n",
            "GDP   |   PROPN   |   proper noun\n",
            "continues   |   VERB   |   verb\n",
            "to   |   PART   |   particle\n",
            "increase   |   VERB   |   verb\n",
            ",   |   PUNCT   |   punctuation\n",
            "we   |   PRON   |   pronoun\n",
            "are   |   AUX   |   auxiliary\n",
            "innovating   |   VERB   |   verb\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "investing   |   VERB   |   verb\n",
            "across   |   ADP   |   adposition\n",
            "diverse   |   ADJ   |   adjective\n",
            "\n",
            "   |   SPACE   |   space\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "growing   |   VERB   |   verb\n",
            "markets   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "with   |   ADP   |   adposition\n",
            "a   |   DET   |   determiner\n",
            "common   |   ADJ   |   adjective\n",
            "underlying   |   VERB   |   verb\n",
            "technology   |   NOUN   |   noun\n",
            "stack   |   NOUN   |   noun\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "an   |   DET   |   determiner\n",
            "operating   |   NOUN   |   noun\n",
            "model   |   NOUN   |   noun\n",
            "that   |   PRON   |   pronoun\n",
            "reinforces   |   VERB   |   verb\n",
            "a   |   DET   |   determiner\n",
            "\n",
            "   |   SPACE   |   space\n",
            "common   |   ADJ   |   adjective\n",
            "strategy   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "culture   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "sense   |   NOUN   |   noun\n",
            "of   |   ADP   |   adposition\n",
            "purpose   |   NOUN   |   noun\n",
            ".   |   PUNCT   |   punctuation\n",
            "”   |   PUNCT   |   punctuation\n",
            "\n",
            "   |   SPACE   |   space\n",
            "“   |   PUNCT   |   punctuation\n",
            "Solid   |   ADJ   |   adjective\n",
            "commercial   |   ADJ   |   adjective\n",
            "execution   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "represented   |   VERB   |   verb\n",
            "by   |   ADP   |   adposition\n",
            "strong   |   ADJ   |   adjective\n",
            "bookings   |   NOUN   |   noun\n",
            "growth   |   NOUN   |   noun\n",
            "driven   |   VERB   |   verb\n",
            "by   |   ADP   |   adposition\n",
            "long   |   ADJ   |   adjective\n",
            "-   |   PUNCT   |   punctuation\n",
            "term   |   NOUN   |   noun\n",
            "Azure   |   ADJ   |   adjective\n",
            "commitments   |   NOUN   |   noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "\n",
            "   |   SPACE   |   space\n",
            "increased   |   VERB   |   verb\n",
            "Microsoft   |   PROPN   |   proper noun\n",
            "Cloud   |   PROPN   |   proper noun\n",
            "revenue   |   NOUN   |   noun\n",
            "to   |   ADP   |   adposition\n",
            "$   |   SYM   |   symbol\n",
            "22.1   |   NUM   |   numeral\n",
            "billion   |   NUM   |   numeral\n",
            ",   |   PUNCT   |   punctuation\n",
            "up   |   ADV   |   adverb\n",
            "32   |   NUM   |   numeral\n",
            "%   |   NOUN   |   noun\n",
            "year   |   NOUN   |   noun\n",
            "over   |   ADP   |   adposition\n",
            "year   |   NOUN   |   noun\n",
            "”   |   PUNCT   |   punctuation\n",
            "said   |   VERB   |   verb\n",
            "Amy   |   PROPN   |   proper noun\n",
            "Hood   |   PROPN   |   proper noun\n",
            ",   |   PUNCT   |   punctuation\n",
            "executive   |   ADJ   |   adjective\n",
            "\n",
            "   |   SPACE   |   space\n",
            "vice   |   NOUN   |   noun\n",
            "president   |   NOUN   |   noun\n",
            "and   |   CCONJ   |   coordinating conjunction\n",
            "chief   |   ADJ   |   adjective\n",
            "financial   |   ADJ   |   adjective\n",
            "officer   |   NOUN   |   noun\n",
            "of   |   ADP   |   adposition\n",
            "Microsoft   |   PROPN   |   proper noun\n",
            ".   |   PUNCT   |   punctuation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = []\n",
        "\n",
        "for token in doc:\n",
        "    if token.pos_ not in [\"SPACE\", \"PUNCT\", \"X\"]:\n",
        "        filtered_tokens.append(token)"
      ],
      "metadata": {
        "id": "Kv8-LCmX45s1"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WGcmBeUG4QI5",
        "outputId": "3863bf6b-2b6c-4827-fd8c-44928cd2009d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Microsoft,\n",
              " Corp.,\n",
              " today,\n",
              " announced,\n",
              " the,\n",
              " following,\n",
              " results,\n",
              " for,\n",
              " the,\n",
              " quarter]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = doc.count_by(spacy.attrs.POS)\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K8A9teQM4_Sb",
        "outputId": "9741b6ef-d6b8-4d3d-a982-016419449036"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{96: 12,\n",
              " 92: 46,\n",
              " 100: 23,\n",
              " 90: 9,\n",
              " 85: 17,\n",
              " 93: 16,\n",
              " 97: 27,\n",
              " 103: 17,\n",
              " 84: 22,\n",
              " 87: 6,\n",
              " 99: 5,\n",
              " 89: 12,\n",
              " 86: 3,\n",
              " 94: 3,\n",
              " 95: 2}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc.vocab[96].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-tubYMvE5IT7",
        "outputId": "df43f02a-cb43-46a5-949f-c7a6c0f85e6e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PROPN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain(doc.vocab[96].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fL-jyQt55LWL",
        "outputId": "86fd067d-aacb-4f2d-9ca6-8f09d9b41c04"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'proper noun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total count:\")\n",
        "for k,v in count.items():\n",
        "    print(doc.vocab[k].text, \":\", v, \"|\", spacy.explain(doc.vocab[k].text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VxsdRvPE5WFr",
        "outputId": "0296b4f0-a8ed-4b24-c1d5-a7f2afb4fc67"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count:\n",
            "PROPN : 12 | proper noun\n",
            "NOUN : 46 | noun\n",
            "VERB : 23 | verb\n",
            "DET : 9 | determiner\n",
            "ADP : 17 | adposition\n",
            "NUM : 16 | numeral\n",
            "PUNCT : 27 | punctuation\n",
            "SPACE : 17 | space\n",
            "ADJ : 22 | adjective\n",
            "AUX : 6 | auxiliary\n",
            "SYM : 5 | symbol\n",
            "CCONJ : 12 | coordinating conjunction\n",
            "ADV : 3 | adverb\n",
            "PART : 3 | particle\n",
            "PRON : 2 | pronoun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag Of Words"
      ],
      "metadata": {
        "id": "zXbHy9JTlyZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = [\"How to Make a girl Happy? It's not at all diff...\",\n",
        "\"We made it! Eta at taunton is 12:30 as planned...\",\n",
        "\"Beautiful truth : Expression of the face could...\",\n",
        "\"Oh:) as usual vijay film or its different?\"]"
      ],
      "metadata": {
        "id": "cAoqpu-W5t9J"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "v = CountVectorizer()\n",
        "\n",
        "l_cv = v.fit_transform(l)"
      ],
      "metadata": {
        "id": "Tf_ap-cDmSxJ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6emsmsEVmZxn",
        "outputId": "769968f2-29f1-4804-9d68-bfa62df2b2fd"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x33 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 36 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_array = l_cv.toarray()\n",
        "l_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TpzOxz5rmbmy",
        "outputId": "acf278f2-715a-4049-a2f7-1bd64626be31"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H6zQgM6Omhox",
        "outputId": "8120cfac-3320-425e-c1b1-7cbd0e60df12"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z2jiYNCdmr-0",
        "outputId": "fe07c55c-0576-438f-81ed-f5eadc475fe4"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['12', '30', 'all', 'as', 'at', 'beautiful', 'could', 'diff',\n",
              "       'different', 'eta', 'expression', 'face', 'film', 'girl', 'happy',\n",
              "       'how', 'is', 'it', 'its', 'made', 'make', 'not', 'of', 'oh', 'or',\n",
              "       'planned', 'taunton', 'the', 'to', 'truth', 'usual', 'vijay', 'we'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for each word, index number is created\n",
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JVe0s-4Kmynx",
        "outputId": "351d745d-9bb4-4d26-9c13-ae1380d7fd8e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'how': 15,\n",
              " 'to': 28,\n",
              " 'make': 20,\n",
              " 'girl': 13,\n",
              " 'happy': 14,\n",
              " 'it': 17,\n",
              " 'not': 21,\n",
              " 'at': 4,\n",
              " 'all': 2,\n",
              " 'diff': 7,\n",
              " 'we': 32,\n",
              " 'made': 19,\n",
              " 'eta': 9,\n",
              " 'taunton': 26,\n",
              " 'is': 16,\n",
              " '12': 0,\n",
              " '30': 1,\n",
              " 'as': 3,\n",
              " 'planned': 25,\n",
              " 'beautiful': 5,\n",
              " 'truth': 29,\n",
              " 'expression': 10,\n",
              " 'of': 22,\n",
              " 'the': 27,\n",
              " 'face': 11,\n",
              " 'could': 6,\n",
              " 'oh': 23,\n",
              " 'usual': 30,\n",
              " 'vijay': 31,\n",
              " 'film': 12,\n",
              " 'or': 24,\n",
              " 'its': 18,\n",
              " 'different': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.get_feature_names_out()[31]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QKz1TcGWm0wR",
        "outputId": "006a0675-e658-4e1f-a2a4-b89eef6bfec9"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vijay'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop words"
      ],
      "metadata": {
        "id": "FquFXrnuG3XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "MX7-DxMKm6ei"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS"
      ],
      "metadata": {
        "id": "CiDNQAGKnHVD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ec343757-3f2b-43a5-e5dd-3ad67a7a27d1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'d\",\n",
              " \"'ll\",\n",
              " \"'m\",\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " \"'ve\",\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amount',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anywhere',\n",
              " 'are',\n",
              " 'around',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'both',\n",
              " 'bottom',\n",
              " 'but',\n",
              " 'by',\n",
              " 'ca',\n",
              " 'call',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'could',\n",
              " 'did',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'done',\n",
              " 'down',\n",
              " 'due',\n",
              " 'during',\n",
              " 'each',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'eleven',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'empty',\n",
              " 'enough',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'except',\n",
              " 'few',\n",
              " 'fifteen',\n",
              " 'fifty',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'former',\n",
              " 'formerly',\n",
              " 'forty',\n",
              " 'four',\n",
              " 'from',\n",
              " 'front',\n",
              " 'full',\n",
              " 'further',\n",
              " 'get',\n",
              " 'give',\n",
              " 'go',\n",
              " 'had',\n",
              " 'has',\n",
              " 'have',\n",
              " 'he',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'hundred',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'indeed',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'keep',\n",
              " 'last',\n",
              " 'latter',\n",
              " 'latterly',\n",
              " 'least',\n",
              " 'less',\n",
              " 'made',\n",
              " 'make',\n",
              " 'many',\n",
              " 'may',\n",
              " 'me',\n",
              " 'meanwhile',\n",
              " 'might',\n",
              " 'mine',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'move',\n",
              " 'much',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " \"n't\",\n",
              " 'name',\n",
              " 'namely',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'next',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'n‘t',\n",
              " 'n’t',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'part',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'please',\n",
              " 'put',\n",
              " 'quite',\n",
              " 'rather',\n",
              " 're',\n",
              " 'really',\n",
              " 'regarding',\n",
              " 'same',\n",
              " 'say',\n",
              " 'see',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'serious',\n",
              " 'several',\n",
              " 'she',\n",
              " 'should',\n",
              " 'show',\n",
              " 'side',\n",
              " 'since',\n",
              " 'six',\n",
              " 'sixty',\n",
              " 'so',\n",
              " 'some',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhere',\n",
              " 'still',\n",
              " 'such',\n",
              " 'take',\n",
              " 'ten',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " 'third',\n",
              " 'this',\n",
              " 'those',\n",
              " 'though',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'to',\n",
              " 'together',\n",
              " 'too',\n",
              " 'top',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'twelve',\n",
              " 'twenty',\n",
              " 'two',\n",
              " 'under',\n",
              " 'unless',\n",
              " 'until',\n",
              " 'up',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'used',\n",
              " 'using',\n",
              " 'various',\n",
              " 'very',\n",
              " 'via',\n",
              " 'was',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'whatever',\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'whither',\n",
              " 'who',\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'within',\n",
              " 'without',\n",
              " 'would',\n",
              " 'yet',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " '‘d',\n",
              " '‘ll',\n",
              " '‘m',\n",
              " '‘re',\n",
              " '‘s',\n",
              " '‘ve',\n",
              " '’d',\n",
              " '’ll',\n",
              " '’m',\n",
              " '’re',\n",
              " '’s',\n",
              " '’ve'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k6EpnLB4JljF",
        "outputId": "260e59a7-c4f2-47ad-dcf2-13c22f9daca6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc = nlp(\"We just opened our wings, the flying part is coming soon\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x7QIOsyBJqJF",
        "outputId": "a80ae41a-6fb3-47bd-9445-8fbb5cc1e030"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "We just opened our wings, the flying part is coming soon"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if token.is_stop:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fYr-Ii_7Jxgx",
        "outputId": "b46a85ac-97b7-471b-c68d-2c576e63af44"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We\n",
            "just\n",
            "our\n",
            "the\n",
            "part\n",
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  doc = nlp(text)\n",
        "\n",
        "  no_stop_words = [token.text for token in doc if not token.is_stop]\n",
        "  return \" \".join(no_stop_words)"
      ],
      "metadata": {
        "id": "aE2gW7-YJ0Af"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"Musk wants time to prepare for a trial over his\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4IMkd137J8Ej",
        "outputId": "d00491a8-1aac-44dc-d3ad-7d7e4a33c8ac"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Musk wants time prepare trial'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"The other is not other but your divine brother\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hraX73xFKAbJ",
        "outputId": "c5866dc0-1917-451f-d909-20484c34e4c0"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'divine brother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Sentiment Analysis, Language Translation or Chat Bot problems removing stop words doesn't make sense. For example"
      ],
      "metadata": {
        "id": "EjubnlXNKGuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"this is not a good movie\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOBAuiB5KCHo",
        "outputId": "20124715-13e9-4d24-b012-fc62fa377e09"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good movie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of N Grams"
      ],
      "metadata": {
        "id": "l41Q087IRBMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "v = CountVectorizer()"
      ],
      "metadata": {
        "id": "Zj8WoaMoKZpk"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for each word index number is generated\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D2217uzsRHMQ",
        "outputId": "2bed9c99-a4c5-4b27-ac06-e10503bb3d9d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = CountVectorizer(ngram_range=(1,2))\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-TKLLs61RYmZ",
        "outputId": "80bfb46b-f115-4c36-9575-2cb94f3eaa38"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 9,\n",
              " 'hathodawala': 2,\n",
              " 'is': 4,\n",
              " 'looking': 7,\n",
              " 'for': 0,\n",
              " 'job': 6,\n",
              " 'thor hathodawala': 10,\n",
              " 'hathodawala is': 3,\n",
              " 'is looking': 5,\n",
              " 'looking for': 8,\n",
              " 'for job': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = CountVectorizer(ngram_range=(1,3))\n",
        "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0IRCPkxeRa-h",
        "outputId": "a28b379d-d097-4e7c-e1fa-81bf97fd90ac"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 12,\n",
              " 'hathodawala': 2,\n",
              " 'is': 5,\n",
              " 'looking': 9,\n",
              " 'for': 0,\n",
              " 'job': 8,\n",
              " 'thor hathodawala': 13,\n",
              " 'hathodawala is': 3,\n",
              " 'is looking': 6,\n",
              " 'looking for': 10,\n",
              " 'for job': 1,\n",
              " 'thor hathodawala is': 14,\n",
              " 'hathodawala is looking': 4,\n",
              " 'is looking for': 7,\n",
              " 'looking for job': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Thor ate pizza\",\n",
        "    \"Loki is tall\",\n",
        "    \"Loki is eating pizza\"\n",
        "]"
      ],
      "metadata": {
        "id": "p4UEXQ9qS66h"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "dDg7nl3mS9aV"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  # remove stop words and lemmatize the text\n",
        "  doc = nlp(text)\n",
        "  filtered_tokens = []\n",
        "  for token in doc:\n",
        "    if token.is_stop or token.is_punct:\n",
        "      continue\n",
        "    filtered_tokens.append(token.lemma_)\n",
        "\n",
        "  return \" \".join(filtered_tokens)"
      ],
      "metadata": {
        "id": "pTyIHMs4TAsw"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"Thor ate pizza\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QtaHVYfgTKqm",
        "outputId": "39e8cf36-3514-4be5-9955-4cdfba0d62f9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thor eat pizza'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"Loki is eating pizza\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8Ep8JqYcTMUh",
        "outputId": "0e413015-354d-4713-d5e8-fad5f1029bf6"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Loki eat pizza'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_processed = [preprocess(text) for text in corpus]\n",
        "corpus_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eRFEcmNSTNwx",
        "outputId": "6330695a-8125-4b53-e8de-671578b08fb8"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thor eat pizza', 'Loki tall', 'Loki eat pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = CountVectorizer(ngram_range=(1,2))\n",
        "v.fit(corpus_processed)\n",
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xKWmsTyUTSmx",
        "outputId": "ef1fe816-e77d-4c0e-cb64-fd91797e7542"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 7,\n",
              " 'eat': 0,\n",
              " 'pizza': 5,\n",
              " 'thor eat': 8,\n",
              " 'eat pizza': 1,\n",
              " 'loki': 2,\n",
              " 'tall': 6,\n",
              " 'loki tall': 4,\n",
              " 'loki eat': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.transform([\"Thor eat pizza\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zJZ1yF1NTVdy",
        "outputId": "6e0bd296-099a-4014-bead-2079084895ed"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out Of Vocabulary (OOV) Term\n",
        "\n",
        "Eg: Hulk"
      ],
      "metadata": {
        "id": "098ItFE0TsaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v.transform([\"Hulk eat pizza\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zVcbqM0cTy_I",
        "outputId": "aaae2920-5a09-4e70-ea91-3f97442e786e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Representation: TF-IDF"
      ],
      "metadata": {
        "id": "J6-s2ZDb6QnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is TF-IDF?\n",
        "\n",
        "TF stands for Term Frequency and denotes the ratio of number of times a particular word\n",
        "appeared in a Document to total number of words in the document.\n",
        "\n",
        "Term Frequency(TF) = [number of times word appeared /\n",
        "total no of words in a document]\n",
        "\n",
        "Term Frequency values ranges between 0 and 1.\n",
        "\n",
        "If a word occurs more number of times,\n",
        "then it's value will be close to 1.\n",
        "\n",
        "IDF stands for Inverse Document Frequency and denotes the log of ratio of total\n",
        "number of documents/datapoints in the whole dataset to the number of documents that\n",
        "contains the particular word.\n",
        "\n",
        "Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
        "\n",
        "In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
        "\n",
        "Finally:\n",
        "\n",
        "TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
      ],
      "metadata": {
        "id": "gBVYtCBV6np2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "_PqXU5Jw6UbL"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
        "    \"Apple is announcing new iphone tomorrow\",\n",
        "    \"Tesla is announcing new model-3 tomorrow\",\n",
        "    \"Google is announcing new pixel-6 tomorrow\",\n",
        "    \"Microsoft is announcing new surface tomorrow\",\n",
        "    \"Amazon is announcing new eco-dot tomorrow\",\n",
        "    \"I am eating biryani and you are eating grapes\"\n",
        "]"
      ],
      "metadata": {
        "id": "nyw5WRGz7U_l"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = TfidfVectorizer()\n",
        "v.fit(corpus)\n",
        "transform_output = v.transform(corpus)"
      ],
      "metadata": {
        "id": "-qtpv2Bq7WdS"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YnBtBiQH7ZEj",
        "outputId": "8fde2d34-533a-483d-a41b-2f20426d05a1"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'thor': 25,\n",
              " 'eating': 10,\n",
              " 'pizza': 22,\n",
              " 'loki': 17,\n",
              " 'is': 16,\n",
              " 'ironman': 15,\n",
              " 'ate': 7,\n",
              " 'already': 0,\n",
              " 'apple': 5,\n",
              " 'announcing': 4,\n",
              " 'new': 20,\n",
              " 'iphone': 14,\n",
              " 'tomorrow': 26,\n",
              " 'tesla': 24,\n",
              " 'model': 19,\n",
              " 'google': 12,\n",
              " 'pixel': 21,\n",
              " 'microsoft': 18,\n",
              " 'surface': 23,\n",
              " 'amazon': 2,\n",
              " 'eco': 11,\n",
              " 'dot': 9,\n",
              " 'am': 1,\n",
              " 'biryani': 8,\n",
              " 'and': 3,\n",
              " 'you': 27,\n",
              " 'are': 6,\n",
              " 'grapes': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IPLVCsjN7dFD",
        "outputId": "0b904255-17f5-45c5-a0e8-043d966d27a2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['already', 'am', 'amazon', 'and', 'announcing', 'apple', 'are',\n",
              "       'ate', 'biryani', 'dot', 'eating', 'eco', 'google', 'grapes',\n",
              "       'iphone', 'ironman', 'is', 'loki', 'microsoft', 'model', 'new',\n",
              "       'pixel', 'pizza', 'surface', 'tesla', 'thor', 'tomorrow', 'you'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_feature_names = v.get_feature_names_out()\n",
        "\n",
        "for word in all_feature_names:\n",
        "\n",
        "    #let's get the index in the vocabulary\n",
        "    indx = v.vocabulary_.get(word)\n",
        "\n",
        "    #get the score\n",
        "    idf_score = v.idf_[indx]\n",
        "\n",
        "    print(f\"{word} : {idf_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "moj7zMqM7lKD",
        "outputId": "6c4814bf-ba81-4f32-d6c7-375b7e639ab7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "already : 2.39\n",
            "am : 2.39\n",
            "amazon : 2.39\n",
            "and : 2.39\n",
            "announcing : 1.29\n",
            "apple : 2.39\n",
            "are : 2.39\n",
            "ate : 2.39\n",
            "biryani : 2.39\n",
            "dot : 2.39\n",
            "eating : 1.98\n",
            "eco : 2.39\n",
            "google : 2.39\n",
            "grapes : 2.39\n",
            "iphone : 2.39\n",
            "ironman : 2.39\n",
            "is : 1.13\n",
            "loki : 2.39\n",
            "microsoft : 2.39\n",
            "model : 2.39\n",
            "new : 1.29\n",
            "pixel : 2.39\n",
            "pizza : 2.39\n",
            "surface : 2.39\n",
            "tesla : 2.39\n",
            "thor : 2.39\n",
            "tomorrow : 1.29\n",
            "you : 2.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_output.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qaceVpJ78JiV",
        "outputId": "2d5a2d99-d7dc-46c6-bf18-b180fa4d7e9d"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
              "        0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
              "        0.24266547, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
              "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.5680354 ,\n",
              "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
              "        0.30652086, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30652086, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26982671, 0.        , 0.        , 0.5680354 ,\n",
              "        0.30652086, 0.        , 0.        , 0.        , 0.5680354 ,\n",
              "        0.        , 0.30652086, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.5680354 , 0.        , 0.        ,\n",
              "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
              "        0.30652086, 0.5680354 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30652086, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26982671, 0.        , 0.5680354 , 0.        ,\n",
              "        0.30652086, 0.        , 0.        , 0.5680354 , 0.        ,\n",
              "        0.        , 0.30652086, 0.        ],\n",
              "       [0.        , 0.        , 0.49391316, 0.        , 0.26652333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.49391316,\n",
              "        0.        , 0.49391316, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.23461736, 0.        , 0.        , 0.        ,\n",
              "        0.26652333, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.26652333, 0.        ],\n",
              "       [0.        , 0.33794257, 0.        , 0.33794257, 0.        ,\n",
              "        0.        , 0.33794257, 0.        , 0.33794257, 0.        ,\n",
              "        0.56104271, 0.        , 0.        , 0.33794257, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33794257]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_output.toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aHHyyVdQ8KPT",
        "outputId": "86d2c23c-7e51-4735-ed2e-44d3bf7b6d15"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
              "       0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
              "       0.24266547, 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ],
      "metadata": {
        "id": "uHEB8uAa_xRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "MkmJ7toR8Saj"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"dog cat banana prashanth\") #here prashanth is not a familiar word(out of vocabulary)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, \" | \", \"Vector:\", token.has_vector, \" | \", \"OOV:\", token.is_oov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BSFRD9RO_7IQ",
        "outputId": "a583f756-4ec2-4419-daa0-ad556958228a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog  |  Vector: True  |  OOV: False\n",
            "cat  |  Vector: True  |  OOV: False\n",
            "banana  |  Vector: True  |  OOV: False\n",
            "prashanth  |  Vector: False  |  OOV: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Each word vector has dimension 300\n",
        "doc[0].vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vsworVLFAh8c",
        "outputId": "8f5af629-9b9a-4d3a-8431-255ac4a7ddd4"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[1].vector.shape #for cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wCbi9ZbXAnyf",
        "outputId": "8178ec70-0401-4cbc-b6be-99fce93037ac"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_token = nlp(\"bread\")\n",
        "base_token.vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DVUd222wAreP",
        "outputId": "b79af0a2-fe38-46e1-9156-6718a78e4771"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing the words similarity with the base token\n",
        "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"{token.text} <-> {base_token.text}:\", token.similarity(base_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0IEbRq-QAvG-",
        "outputId": "4e7c43b1-088c-4a4b-91e9-2b59fd83d66a"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bread <-> bread: 1.0\n",
            "sandwich <-> bread: 0.6341067010130894\n",
            "burger <-> bread: 0.47520687769584247\n",
            "car <-> bread: 0.06451533308853552\n",
            "tiger <-> bread: 0.04764611675903374\n",
            "human <-> bread: 0.2151154210812192\n",
            "wheat <-> bread: 0.6150360888607199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_similarity(base_word, words_to_compare):\n",
        "    base_token = nlp(base_word)\n",
        "    doc = nlp(words_to_compare)\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} <-> {base_token.text}: \", token.similarity(base_token))"
      ],
      "metadata": {
        "id": "cF4ks2SPA183"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_similarity(\"iphone\", \"apple samsung iphone dog kitten\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GABAW6-2A7cy",
        "outputId": "d9f4b966-9ad0-4994-c984-ebacc4ad1b27"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple <-> iphone:  0.3634123187833088\n",
            "samsung <-> iphone:  0.6683552428198852\n",
            "iphone <-> iphone:  1.0\n",
            "dog <-> iphone:  0.062353975727114645\n",
            "kitten <-> iphone:  0.09053956522798948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "king = nlp.vocab[\"king\"].vector\n",
        "man = nlp.vocab[\"man\"].vector\n",
        "woman = nlp.vocab[\"woman\"].vector\n",
        "queen = nlp.vocab[\"queen\"].vector\n",
        "\n",
        "result = king - man + woman"
      ],
      "metadata": {
        "id": "BOYSTy0GA-d-"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity([result], [queen])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Lsf4GuqZBC1P",
        "outputId": "5e36b5ff-e36e-4713-c7d7-71c561dfbce7"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.61780137]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank you**"
      ],
      "metadata": {
        "id": "iRL8GwteDYI5"
      }
    }
  ]
}